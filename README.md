# Awesome Unlearnable Examples [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A curated list of awesome Unlearnable Example papers.


## Papers

- **LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples**, Y. Liu et al. [[pdf]](https://arxiv.org/pdf/2512.07375)
- **Towards Provably Unlearnable Examples via Bayes Error Optimisation**, R. Zhang et al. [[pdf]](https://arxiv.org/pdf/2511.08191)
- **T2UE: Generating Unlearnable Examples from Text Descriptions**, X. Ma et al. [[pdf]](https://arxiv.org/pdf/2508.03091)
- **Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking**, Q. Wu et al. [[pdf]](https://arxiv.org/pdf/2507.07483)
- **ARMOR: Shielding Unlearnable Examples against Data Augmentation** (2025), X. Gong et al. [[pdf]](https://arxiv.org/abs/2501.08862)
- **Scale-up Unlearnable Examples Learning with High-Performance Computing** (2025), Y. Zhu et al. [[pdf]](https://arxiv.org/abs/2501.06080)
- **Purify Unlearnable Examples via Rate-Constrained Variational Autoencoders** (2024), Y. Yu et al. [[pdf]](https://arxiv.org/abs/2405.01460)
- **Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise** (2023), Y. Liu et al.  [[pdf]](https://arxiv.org/abs/2311.13091)
- **Segue: Side-information Guided Generative Unlearnable Examples for Facial Privacy Protection in Real World** (2023), Z. Zhang et al.  [[pdf]](https://arxiv.org/abs/2310.16061)
- **Re-thinking Data Availablity Attacks Against Deep Neural Networks** (2023), B. Fang et al. [[pdf]](https://arxiv.org/abs/2305.10691)
- **Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples** (2023), W. Jiang et al.  [[pdf]](https://arxiv.org/abs/2305.09241)
- **Towards Generalizable Data Protection With Transferable Unlearnable Examples**  (2023), B. Fang et al. [[pdf]](https://arxiv.org/abs/2305.11191)
- **Unlearnable Examples for Diffusion Models: Protect Data from Unauthorized Exploitation** (2023), Z. Zhao et al. [pdf](https://arxiv.org/abs/2306.01902)
- **Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable Example Attacks** (2023) T. Qin et al. [[pdf]](https://arxiv.org/abs/2303.15127)
- **Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples** (2022), J. Zhang et al. [[pdf]](https://arxiv.org/abs/2301.01217)
- **One-Pixel Shortcut: on the Learning Preference of Deep Neural Networks** (2022), S. Wu et al. [[pdf]](https://arxiv.org/abs/2205.12141)
- **Transferable Unlearnable Examples** (2022), J. Ren et al. [[pdf]](https://arxiv.org/abs/2210.10114)
- **Robust Unlearnable Examples: Protecting Data Against Adversarial Learning** (2022), S. Fu et al. [[pdf]](https://arxiv.org/abs/2203.14533)
- **Going Grayscale: The Road to Understanding and Improving Unlearnable Examples** (2021), Z. Liu et al. [[pdf]](https://arxiv.org/abs/2111.13244)
- **Unlearnable Examples: Making Personal Data Unexploitable** (2021), H. Huang et al. [[pdf]](https://arxiv.org/abs/2101.04898)
